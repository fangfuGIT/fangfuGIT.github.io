---
layout: post
title:  "HBase笔记"
date:   2020-03-04 11:39:21
categories:  HBase
tags: HBase
excerpt: 
mathjax: true
---


HBase架构和原理
参考文章：
https://www.jianshu.com/p/9d3d388eae19
https://www.jianshu.com/p/56b83585d8ce

HBase 是列式存储，和 MySQL 的行式存储不一样。相比较而言，列式存储不会存储空数据，每行数据以key-value形式存储，可以同时存储上百万行

HBase 中有列簇概念，同一个列簇下的列存储在一起，在 Region 的一个 StoreFile 中。

HBase 是按照 Rowkey 进行查找，要查询的字段要想办法放到 Rowkey 中。

HBase 内部使用 LSM 三层模型进行存储，数据先写到内存的 MemStore 中，内存达到一定阈值再刷写到硬盘 StoreFile中，再满足一定条件时，小的 StoreFile 会合并为大的 StoreFile。StoreFile的底层是以HFile的格式存储的。   

HBase WAL机制，数据写入内存的同时记下日志（HLog）。可以通过日志恢复策略保证内存数据不丢失。

HDFS 不能随机修改文件。HBase的存储是基于HDFS的。在HBase的数据修改和删除操作，实际上是新增一条时间更新的记录，通过timestamp来标识。旧的数据记录会在大合并时（Major Compact）被清理删除。数据量大的时候，大合并比较耗性能。

HBase中每一张表都会有元信息，存储在元信息表，也叫meta表。这个表是系统表，保存在zookeeper上。

HBase 写入数据的过程。先从meta表取元信息。根据Rowkey找到应该写入哪个RegionServer。然后写入这个RegionServer对应的内存MemStore中，同时记录操作日志WAL。当MemStore超过一定阈值，会将内存中数据写入硬盘StoreFile中，在一定条件下，小的StoreFile会合并成大的StoreFile，便于数据在HDFS中存储。如果有大量Rowkey相近的数据都被分配到同一个Region，导致数据过大，Region会拆分。HMaster会对拆分后的Region重新分配RegionServer。    

HBase 读取数据的过程。先从meta获取元信息，确认要查的数据在哪些RegionServer上，分别在这些RegionServer上根据列簇进行StoreFile和MemStore的查找。查找出来以后根据timestamp返回最新的数据。

HBase 适合 OLAP 类的应用。侧重分析，对事务要求低。   

HBase安装

下载hbase-2.0.5
```
wget http://archive.apache.org/dist/hbase/2.0.5/hbase-2.0.5-bin.tar.gz
tar zxvf hbase-2.0.5-bin.tar.gz -C /usr/local
```
下载hbase-2.0.0
```
wget http://archive.apache.org/dist/hbase/2.0.0/hbase-2.0.0-bin.tar.gz
tar zxvf hbase-2.0.0-bin.tar.gz -C /usr/local
```


注意：以下均为2.0.0为准
安装java环境
```
yum install java-1.8.0-openjdk* -y
```

安装完成后，查看hbase监听的端口，一般是内网IP监听，如果监听的是外网IP需要改成内网IP

方法一：  
vi /usr/local/hbase-2.0.0/conf/regionservers  
改成内网IP地址  

vi /etc/hosts  
添加一行  
本机内网IP hbase_node    

hostnamectl set-hostname hbase_node

重启hbase   

方法二：  

vi  hbase-site.xml
添加下面这段：

```
<property>
<name>hbase.zookeeper.quorum</name>
<value>外网IP地址</value>
</property>
```
重启hbase


进入HBase命令行：
```
./HBase shell
```
HBase shell 区分大小写

help 查看命令帮助

list 查看表

建表   
```
create 'group_msgs','group_msgs'
```

统计表逻辑行数：
```
count 'group_msgs'
```
遍历表:  
```
scan 'group_msgs'
```
清空表但是保留表结构:  
```
truncate 'group_msgs'
```  

删表:
```
disable 'group_msgs'
drop 'group_msgs'
```

查看表是否存在：  
exists 'group_msgs'  

查看表的列族信息：   
describe 'group_msgs'   

查询表中某一列：  
get 'group_msgs','groupId'

HBase 提供了三种查询方式：

全表扫描，scan。
根据一个 Rowkey 进行查询。
根据 Rowkey 过滤的范围查询。

在 HBase 中，列不是固定的表结构，在创建表时，不需要预先定义列名，可以在插入数据时临时创建。   

根据ROW过滤的范围查询：  
scan 'group_msgs',{STARTROW=>'',STOPROW=>''}

协处理器， 使HBase在执行求和、计数、排序等操作将变得更加高效，同时允许用户扩展实现HBase目前所不具备的功能，如权限校验、二级索引、完整性约束等  
协处理器的加载方式：  
全局加载，对所有表生效。  
在HBase-site.yml中添加：  
```
<property>
<name>hbase.coprocessor.user.region.classes</name>
<value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
</property>
```
重启HBase


hbase的数据导出和导入。导出的时候，/data/databak不需要提前创建。导入前需要先手动建表
```
hbase org.apache.hadoop.hbase.mapreduce.Driver export group_msgs file:///data/databak
hbase org.apache.hadoop.hbase.mapreduce.Driver import group_msgs file:///data/databak
```


