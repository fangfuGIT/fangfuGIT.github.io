---
layout: post
title:  "scrapy"
date:   2018-07-4 11:09:00
categories: scrapy
tags: scrapy
excerpt: scrapy
mathjax: true
---

计算机只能处理数字0和1，文本需要转换成数字才能处理，0或1被称为一个bit，
计算机中8个bit作为一个字节。所以通过二进制转换成十进制，一个字节能表示
最大的数字就是255    
计算机是美国人发明的，所以一个字节可以表示所有字符了，所以ASCII
（一个字节）编码就是美国的标准编码   
但是ASCII处理中文明显是不够的，中文不止255个汉字，所以中国制定了
GB2312编码，用两个字节表示一个汉字。GB2312还把ASCII包含进去了，同理，其他
国家为了解决这个问题都发展了一套字节的编码，各自的标准都不同，而且各种标准
也越来越多，如果出现多种语言混合显示就一定会出现乱码。   
unicode的出现解决了这个问题，它可以将所有语言统一到一套编码里   
    
ASCII和unicode编码：    
1、字母A用ASCII编码二进制是0100 0001，十进制是65   
2、汉字“中”超过了ASCII的编码范围，用unicode编码二进制是01001110 00101101，
十进制是20013    
3、A用unicode编码只需要在前面补0，二进制是00000000 0100 0001    
    
乱码问题解决了，但是如果内容全是英文，unicode编码相对于ASCII，存储空间以及传输速度
都大上一倍多，
     
uft-8，把英文变长一个字节，汉字3个字节，生僻字4-6个字节，如果传输大量英文，utf8就有
优势了，相对于unicode可以减少一倍的存储空间，也可以减少传输的数据量。但是在编程中，
utf8就没有unicode在内存中处理的容易，因为utf8长度不一样，但是unicode长度是统一的。   
所以通常我们在读取文件时，需要将utf8转换为unicode，而在我们保存文件的时候，需要将unicode
转换成utf8   
在python2中，要注意编码的转换,下面是在linux中执行的代码：    
```
import sys
sys.getdefaultencoding()
str = "python你好"   
str_u = u"python你好"
str.decode("utf8").encode("utf8")
先把str通过decode转换成unicode，再通过encode转换成utf8
str_u.encode("utf8")
```
在python3中，都是unicode，不需要在定义字符串前面加"u"

     
     
     
```
pip install beautifulsoup4
```   
验证,注意大小写：  
```
from bs4 import BeautifulSoup
```



pycharm建project。
配置git
装环境:   
```
pip install scrapy
```



